# _____________________________________________________________________________________________________________
## Get started with Ollama
Run the following commands
- ```pip install ollama```
- ```sudo snap install ollama```
### Run llama 3.2
```ollama run llama3.2```
# _____________________________________________________________________________________________________________

## installing bitsandbytes
- run `nvcc --version` to get cuda version installed. Example 11.8 then enter 118 in following command
- `export BNB_CUDA_VERSION=118`
- run this `export LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH
`
