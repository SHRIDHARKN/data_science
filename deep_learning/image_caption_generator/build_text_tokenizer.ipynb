{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_path = \"\"\n",
    "data_path = os.path.join(project_path,\"data\")\n",
    "tokenizer_path = os.path.join(data_path,\"tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# captions load\n",
    "captions = open(\"data/captions/captions.txt\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40456/40456 [00:00<00:00, 859803.31it/s]\n"
     ]
    }
   ],
   "source": [
    "img_name_captions_dict = {}\n",
    "\n",
    "for line in tqdm(captions[14:].split('\\n')):\n",
    "    word_tokens = line.split(',')\n",
    "    if len(line)<2:\n",
    "        continue\n",
    "    image_name,caption = word_tokens[0],word_tokens[1:]\n",
    "    image_name = image_name.split('.')[0]\n",
    "\t\n",
    "    caption = \" \".join(caption)\n",
    "    if image_name not in img_name_captions_dict:\n",
    "        img_name_captions_dict[image_name] = []\n",
    "    img_name_captions_dict[image_name].append(caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "\n",
    "    text = text.lower()\n",
    "    text = text.replace('[^A-Za-z]', '')\n",
    "    text = text.replace('\\s+', ' ')\n",
    "    text = 'start  ' + text + '  end'\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img_name,captions in img_name_captions_dict.items():\n",
    "    processed_captions = []\n",
    "    for caption in captions:\n",
    "        processed_caption = preprocess_text(caption)\n",
    "        processed_captions.append(processed_caption)\n",
    "    img_name_captions_dict[img_name] = processed_captions     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "captions_corpus = []\n",
    "for img_name,captions in img_name_captions_dict.items():\n",
    "    captions_corpus.extend(img_name_captions_dict[img_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(captions_corpus)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "max_length = max(len(caption.split()) for caption in captions_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data\\\\tokenizer\\\\tokenizer_details']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_details = {\n",
    "    \"tokenizer\":tokenizer,\n",
    "    \"vocab_size\":vocab_size,\n",
    "    \"max_length\":max_length\n",
    "}\n",
    "\n",
    "joblib.dump(tokenizer_details,os.path.join(tokenizer_path,\"tokenizer_details\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
